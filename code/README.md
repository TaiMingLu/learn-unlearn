
# LoRA Fine-Tuning Trainer

This script fine-tunes models using LoRA, with optional gradient ascent unlearning via `GradientAscentTrainer`.


## Usage

Run the script with:

```bash
python train_script.py [OPTIONS]
```

### Key Arguments

- `--epochs`: Number of epochs (default: `1`)
- `--batch_size`: Batch size (default: `1`)
- `--learning_rate`: Learning rate (default: `2e-4`)
- `--output_dir`: Output directory (default: `./models/`)
- `--dataset_name`: Dataset name (default: `TaiMingLu/news-truthful`)
- `--unlearn`: Use `GradientAscentTrainer` if set to perform unlearning

## Example

```bash
python train_script.py --epochs 1 --batch_size 1 --unlearn
```

